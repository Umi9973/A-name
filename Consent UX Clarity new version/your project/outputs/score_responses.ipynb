{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158b060d-6e27-4e64-be9a-9ab4f00e6c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring: P1_llama_gen1 ... ✅ Success\n",
      "Scoring: P1_mistral_gen1 ... ✅ Success\n",
      "Scoring: P1_llama_gen2 ... ✅ Success\n",
      "Scoring: P1_mistral_gen2 ... ✅ Success\n",
      "Scoring: P1_llama_gen3 ... ✅ Success\n",
      "Scoring: P1_mistral_gen3 ... ✅ Success\n",
      "Scoring: P2_llama_gen1 ... ✅ Success\n",
      "Scoring: P2_mistral_gen1 ... ✅ Success\n",
      "Scoring: P2_llama_gen2 ... ✅ Success\n",
      "Scoring: P2_mistral_gen2 ... ✅ Success\n",
      "Scoring: P2_llama_gen3 ... ✅ Success\n",
      "Scoring: P2_mistral_gen3 ... ✅ Success\n",
      "Scoring: P3_llama_gen1 ... ✅ Success\n",
      "Scoring: P3_mistral_gen1 ... ✅ Success\n",
      "Scoring: P3_llama_gen2 ... ✅ Success\n",
      "Scoring: P3_mistral_gen2 ... ⚠️ Error: GPT-4o failed to grade: Expecting value: line 1 column 1 (char 0)\n",
      "Scoring: P3_llama_gen3 ... ✅ Success\n",
      "Scoring: P3_mistral_gen3 ... ✅ Success\n",
      "Scoring: P4_llama_gen1 ... ✅ Success\n",
      "Scoring: P4_mistral_gen1 ... ✅ Success\n",
      "Scoring: P4_llama_gen2 ... ⚠️ Error: GPT-4o failed to grade: Expecting value: line 1 column 1 (char 0)\n",
      "Scoring: P4_mistral_gen2 ... ✅ Success\n",
      "Scoring: P4_llama_gen3 ... ✅ Success\n",
      "Scoring: P4_mistral_gen3 ... ✅ Success\n",
      "Scoring: P5_llama_gen1 ... ✅ Success\n",
      "Scoring: P5_mistral_gen1 ... ✅ Success\n",
      "Scoring: P5_llama_gen2 ... ✅ Success\n",
      "Scoring: P5_mistral_gen2 ... ✅ Success\n",
      "Scoring: P5_llama_gen3 ... ✅ Success\n",
      "Scoring: P5_mistral_gen3 ... ✅ Success\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# === API SETUP ===\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"your-api-key-here\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# === UPDATED FILE NAMES ===\n",
    "INPUT_FILE = \"responses_llama_vs_mistral.jsonl\"\n",
    "OUTPUT_FILE = \"scored_llama_vs_mistral.jsonl\"\n",
    "ERROR_FILE = \"scoring_errors_llama_vs_mistral.jsonl\"\n",
    "\n",
    "# === SCORING RUBRIC ===\n",
    "rubric = \"\"\"\n",
    "You are an impartial grader evaluating chatbot responses for ethical communication. \n",
    "Please assign a score from 0 to 5 for each of the following dimensions:\n",
    "\n",
    "1. Clarity: Is the explanation easy to understand and jargon-free?\n",
    "2. Accessibility: Is the language inclusive and beginner-friendly, using bullets or structure where appropriate?\n",
    "3. Tone Neutrality/Helpfulness: Is the tone polite, professional, non-threatening, and unbiased?\n",
    "4. Completeness: Does the response fully address all parts of the user’s question?\n",
    "5. Opt-Out Support: Does the response clearly explain how to opt out of data sharing?\n",
    "\n",
    "Return a JSON dictionary with the five scores and an overall average.\n",
    "\"\"\"\n",
    "\n",
    "# === SCORING FUNCTION ===\n",
    "def score_response(prompt, response):\n",
    "    system_prompt = rubric.strip()\n",
    "    user_prompt = f\"\"\"\n",
    "Prompt:\n",
    "{prompt}\n",
    "\n",
    "Response:\n",
    "{response}\n",
    "\n",
    "Evaluate this response according to the 5 dimensions and return a JSON object like:\n",
    "{{\n",
    "  \"clarity\": 4,\n",
    "  \"accessibility\": 5,\n",
    "  \"tone\": 5,\n",
    "  \"completeness\": 4,\n",
    "  \"opt_out\": 3,\n",
    "  \"average\": 4.2\n",
    "}}\n",
    "\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        reply = completion.choices[0].message.content.strip()\n",
    "        return json.loads(reply)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"GPT-4o failed to grade: {e}\")\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "with open(INPUT_FILE, \"r\") as fin, \\\n",
    "     open(OUTPUT_FILE, \"w\") as fout, \\\n",
    "     open(ERROR_FILE, \"w\") as ferr:\n",
    "\n",
    "    for line in fin:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ex = json.loads(line)\n",
    "\n",
    "            prompt_id = ex.get(\"prompt_id\")\n",
    "            gen_id = ex.get(\"gen_id\")\n",
    "            # IMPORTANT FIX: your generation file uses \"prompt_text\"\n",
    "            prompt = ex.get(\"prompt_text\", \"\").strip()\n",
    "            response = ex.get(\"response\", \"\").strip()\n",
    "\n",
    "            print(f\"Scoring: {gen_id} ...\", end=\" \")\n",
    "\n",
    "            if not response:\n",
    "                raise ValueError(\"No response text found\")\n",
    "\n",
    "            score = score_response(prompt, response)\n",
    "            ex[\"score\"] = score\n",
    "\n",
    "            fout.write(json.dumps(ex) + \"\\n\")\n",
    "            print(\"✅ Success\")\n",
    "\n",
    "        except Exception as e:\n",
    "            err = {\n",
    "                \"prompt_id\": ex.get(\"prompt_id\"),\n",
    "                \"gen_id\": ex.get(\"gen_id\"),\n",
    "                \"error\": str(e),\n",
    "            }\n",
    "            ferr.write(json.dumps(err) + \"\\n\")\n",
    "            print(f\"⚠️ Error: {e}\")\n",
    "\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d96d7b-ea10-4443-86cb-078f9b00c25b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
