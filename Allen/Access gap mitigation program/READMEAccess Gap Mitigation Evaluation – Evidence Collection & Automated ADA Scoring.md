# Access Gap Mitigation Evaluation ‚Äì Evidence Collection & Automated ADA Scoring  
*(L4 Fairness Branch: ‚ÄúAccess gap mitigation program‚Äù)*

This repository contains all files required to reproduce the evidence-collection and automated ADA scoring workflow for evaluating **‚ÄúAccess gap mitigation program‚Äù**, an **L4 Fairness branch** in the AI Ethics Index measurement project.

This evaluation follows the **ADA (Automated Document Analysis)** methodology and extracts evidence from authoritative digital-equity, fairness, and governance frameworks, including:  
- WHO *Ethics & Governance of Artificial Intelligence for Health* (2021)  
- OECD *Understanding the Digital Divide* (2001)
- Digital divide frameworks (infrastructure, affordability, literacy, disability access)  
- Accessibility and inclusion guidelines  
- Any additional official documentation used by the model that relates to access gaps or equitable access.

The scoring rubric is fully customized for **access barriers, digital divides, mitigation strategies, and equity governance**, and is implemented in `score_access_gap_mitigation.py`.

---

## üìÅ Repository Structure

| File | Description |
|------|-------------|
| `access_gap_mitigation_prompt.txt` | Reproducible ADA evidence-collection prompt for the L4-3 Access Gap Mitigation branch. |
| `score_access_gap_mitigation.py` | Full pipeline script generating evidence (GPT-4o & Ollama) and performing strict ADA scoring using GPT-4o as judge. |
| `gpt4o_access_gap_mitigation_evidence.txt` | Detailed ADA-style evidence report generated by GPT-4o. |
| `ollama_access_gap_mitigation_evidence.txt` | Detailed ADA-style evidence report generated by the local Ollama model. |
| `gpt4o_access_gap_scoring_weighted.json` | Raw JSON scoring results for GPT-4o evidence. |
| `ollama_access_gap_scoring_weighted.json` | Raw JSON scoring results for Ollama evidence. |
| `gpt4o_access_gap_scoring_weighted.xlsx` | Weighted scoring table for GPT-4o evidence. |
| `ollama_access_gap_scoring_weighted.xlsx` | Weighted scoring table for Ollama evidence. |
| `access_gap_mitigation_scoring_weighted.xlsx` | **Combined scoring table** containing both models' scores. |
| `README.md` | Documentation for methodology and scoring workflow. |

---

## üîÑ Workflow Overview

The workflow consists of **three major stages**, consistent with ADA methodology:

---

### **1. Evidence Collection (ADA ‚Äì Automated Document Analysis)**

Evidence is generated automatically using the structured prompt in  
`access_gap_mitigation_prompt.txt`.

Each model (GPT-4o and Ollama-Mistral) produces a **1500‚Äì2500-word, audit-ready ADA evidence report** covering the following access-gap dimensions:

#### Extracted access-gap mitigation dimensions:
- **Digital divides:** connectivity, affordability, infrastructure, device access  
- **Structural barriers:** economic, geographic, linguistic, disability access  
- **Accessibility & inclusion obligations** under health, digital governance, or regulatory frameworks  
- **Risk management & governance requirements** relating to access, equity, or vulnerable groups  
- **Mitigation strategies:**  
  - capacity building  
  - infrastructure investment  
  - inclusive system design  
  - literacy programs  
  - disability-access enhancements  
  - public‚Äìprivate partnerships  
- **Monitoring, evaluation, and accountability mechanisms**

#### Required sources (verbatim-excerpt-based):
- WHO AI Ethics & Governance in Health (2021)  
- EU Digital Services Act (2022/2065)  
- Digital inclusion frameworks  
- Accessibility regulations  

#### Required structure:
- Overview of Sources  
- Evidence Table (verbatim excerpts + metadata)  
- Analysis of each access-gap dimension  
- Identification of missing disclosures for this branch  

Outputs:
- `gpt4o_access_gap_mitigation_evidence.txt`  
- `ollama_access_gap_mitigation_evidence.txt`

---

### **2. Automated ADA Scoring (Strict Multi-Dimension Rubric)**

Scoring is performed by **GPT-4o**, using a strict six-dimension rubric:

1. **Evidence Extraction Quality**  
2. **Coverage of Access Gap Mitigation Dimensions**  
3. **Structure & Formatting**  
4. **Relevance & Faithfulness**  
5. **Identification of Missing Disclosures**  
6. **Audit Usefulness**

Each criterion is scored **0‚Äì5**, under strict rules:

- **5 = Near-perfect / exceptional (rare)**  
- **4 = Strong but has non-trivial weaknesses**  
- **3 = Adequate but incomplete**  
- **2 = Weak coverage**  
- **1 = Very poor**  
- **0 = No evidence**

Weighted scoring follows the ADA fairness weighting scheme:

| Criterion | Weight |
|----------|--------|
| Evidence Extraction Quality | **0.25** |
| Coverage of Access Gap Mitigation Dimensions | **0.25** |
| Structure & Formatting | 0.15 |
| Relevance & Faithfulness | 0.15 |
| Missing Disclosures | 0.10 |
| Audit Usefulness | 0.10 |

Outputs:
- `gpt4o_access_gap_scoring_weighted.json`  
- `ollama_access_gap_scoring_weighted.json`  
- `gpt4o_access_gap_scoring_weighted.xlsx`  
- `ollama_access_gap_scoring_weighted.xlsx`

---

### **3. Combined Evaluation Output**

Finally, both model results are merged into:

- **`access_gap_mitigation_scoring_weighted.xlsx`**

This combined file is used for:
- Cross-model comparison  
- AI Ethics Index scoring  
- Reporting and audit review  

---

## ‚öôÔ∏è Automated Execution

Run the full access-gap evaluation pipeline with:

```bash
python score_access_gap_mitigation.py
```

This script will:

1. Load `access_gap_mitigation_prompt.txt`  
2. Generate detailed ADA-style evidence (GPT-4o + Ollama)  
3. Save both `.txt` evidence files  
4. Score each evidence report using GPT-4o  
5. Export JSON + Excel score files  
6. Produce a combined scoring output  

All results appear in the same directory.

---

## üîÅ Reproducibility

This evaluation ensures:

- Deterministic evidence-collection prompts  
- A fixed scoring rubric  
- Text-based documentation snapshots for each model  
- JSON + XLSX scoring outputs  
- Fully automated pipeline execution  

Suitable for:
- Cross-model fairness comparison  
- Academic reproducibility  
- AI governance audits  
- Reliability analysis  

---

## üìå Summary

This repository provides:

- Reproducible ADA-based analysis of access gaps  
- Strict, transparent, and auditable scoring rubric  
- Automated multi-model evaluation  
- Combined L4-3 scoring output  
- Full evidence & scoring traceability  

It forms a complete evaluation pipeline for the  
**‚ÄúAccess gap mitigation program‚Äù**  
L4 Fairness branch of the AI Ethics Index.
