# Proxy / Representation Analysis Evaluation ‚Äì Evidence Collection & Automated ADA Scoring  
*(L4 Fairness Branch: ‚ÄúProxy or representation analysis performed where direct attributes unavailable‚Äù)*

This repository contains all files required to reproduce the evidence-collection and automated scoring workflow for evaluating **‚ÄúProxy or representation analysis performed where direct attributes unavailable‚Äù**, an **L4 Fairness branch** in the AI Ethics Index measurement project.

This evaluation follows the **ADA (Automated Document Analysis)** methodology and extracts evidence from authoritative fairness literature and bias-analysis frameworks, including:  
- *Fairness and Machine Learning (Barocas, Hardt, Narayanan)*  
- **NIST SP 1270**  
- any other possible resources or official documentation about this branch from your own database

The scoring rubric is fully customized for **proxy attributes, representational bias, and indirect inference risks** and is implemented in `score_proxy_representation.py`.

---

## üìÅ Repository Structure

| File | Description |
|------|-------------|
| `proxy_representation_prompt.txt` | Reproducible ADA evidence-collection prompt for this L4 branch. |
| `score_proxy_representation.py` | Full pipeline script generating evidence (GPT-4o & Ollama) and performing strict ADA scoring using GPT-4o as judge. |
| `gpt4o_proxy_representation_evidence.txt` | Detailed ADA-style evidence report generated by GPT-4o. |
| `ollama_proxy_representation_evidence.txt` | Detailed ADA-style evidence report generated by the local Ollama model. |
| `gpt4o_proxy_scoring_weighted.json` | Raw JSON scoring results for GPT-4o evidence. |
| `ollama_proxy_scoring_weighted.json` | Raw JSON scoring results for Ollama evidence. |
| `gpt4o_proxy_scoring_weighted.xlsx` | Weighted scoring table for GPT-4o evidence. |
| `ollama_proxy_scoring_weighted.xlsx` | Weighted scoring table for Ollama evidence. |
| `proxy_representation_scoring_weighted.xlsx` | **Combined scoring table** for both models in one file. |
| `README.md` | Documentation for methodology and scoring workflow. |

---

## üîÑ Workflow Overview

The workflow consists of **three major stages**, consistent with ADA standards:

---

### **1. Evidence Collection (ADA ‚Äì Automated Document Analysis)**

Evidence is generated based on the structured prompt in  
`proxy_representation_prompt.txt`.

Each model (GPT-4o and Ollama‚ÄêMistral) produces a **1500‚Äì2500-word, audit-ready ADA evidence report** covering the following proxy-analysis dimensions:

#### Extracted proxy / representation dimensions:
- **What qualifies as a proxy attribute**  
  (e.g., ZIP ‚Üí race, name ‚Üí gender, location ‚Üí SES)
- **Proxy discrimination & representational harm**  
- **Methods for detecting proxy or latent relationships:**  
  - causal graphs  
  - counterfactual fairness  
  - correlation tests  
  - variable-importance analysis  
  - latent variable inference  
- **Risks of indirect inference of protected attributes**  
- **Harms from proxy-based misrepresentation**

#### Required sources:
- *Fairness and Machine Learning*  
- *Counterfactual Fairness (Kusner et al.)*  
- **NIST SP 1270**  
- Other credible fairness or bias-analysis literature  

#### Required structure:
- Overview of sources  
- Evidence table (with long verbatim excerpts)  
- Analysis for each proxy dimension  
- Missing-disclosure section (e.g., lack of proxy testing documentation)

Model outputs:  
- `gpt4o_proxy_representation_evidence.txt`  
- `ollama_proxy_representation_evidence.txt`

---

### **2. Automated ADA Scoring (Strict Rubric)**

Scoring is performed by **GPT-4o**, using a strict six-dimension rubric tailored for proxy-analysis:

1. **Evidence Extraction Quality**  
2. **Coverage of Proxy/Representation Dimensions**  
3. **Structure & Formatting**  
4. **Relevance & Faithfulness**  
5. **Identification of Missing Disclosures**  
6. **Audit Usefulness**

Each criterion is scored **0‚Äì5**, following strict guidelines:
- **5 = Rare / near-perfect**
- **2‚Äì4 = Typical realistic range**
- **0‚Äì1 = Weak or missing**

Weighted scores follow the official ADA weighting scheme:

| Criterion | Weight |
|----------|--------|
| Evidence Extraction Quality | **0.25** |
| Coverage of Proxy Dimensions | **0.25** |
| Structure & Formatting | 0.15 |
| Relevance & Faithfulness | 0.15 |
| Missing Disclosures | 0.10 |
| Audit Usefulness | 0.10 |

Outputs:
- `gpt4o_proxy_scoring_weighted.json`  
- `ollama_proxy_scoring_weighted.json`  
- `gpt4o_proxy_scoring_weighted.xlsx`  
- `ollama_proxy_scoring_weighted.xlsx`

---

### **3. Combined Evaluation Output**

The script automatically merges scoring results from both models into:

- **`proxy_representation_scoring_weighted.xlsx`**

This combined file is designed for:
- Cross-model comparison  
- Integration into the AI Ethics Index scoring system  
- Transparent audit review  

---

## ‚öôÔ∏è Automated Execution

Run the full evaluation pipeline with:

```bash
python score_proxy_representation.py
```

This script performs the following steps:

1. Load `proxy_representation_prompt.txt`  
2. Generate detailed evidence reports (GPT-4o & Ollama)  
3. Save generated `.txt` evidence files  
4. Score both evidence reports using GPT-4o  
5. Export JSON + Excel scoring outputs  
6. Produce a combined scoring file  

All outputs are saved in the same directory.

---

## üîÅ Reproducibility

The repository ensures:

- Deterministic evidence-collection prompts  
- Fixed scoring rubric  
- Text-based evidence snapshots for each model  
- JSON + Excel scoring results  
- Fully automated pipeline (`score_proxy_representation.py`)  

Suitable for:
- Auditable fairness evaluations  
- Cross-model performance comparisons  
- Reproducibility in academic / compliance settings  

---

## üìå Summary

This repository provides:

- Reproducible ADA-based proxy/representation analysis  
- Strict, transparent, and audit-ready scoring rubric  
- Automated multi-model scoring  
- Combined L4-2 evaluation output  
- Full evidence and scoring traceability  

It forms a complete evaluation pipeline for the  
**‚ÄúProxy or representation analysis performed where direct attributes unavailable‚Äù**  
L4 Fairness branch of the AI Ethics Index.
