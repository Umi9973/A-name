# Overview of Sources

The following sources provide information regarding the dataset representativeness, including demographic coverage, geographic/locale distribution, language distribution, sampling and data collection procedures, and identified limitations.

| Source Name          | Source Type            | URL or Reference                                                                              |
|----------------------|------------------------|----------------------------------------------------------------------------------------------|
| Datasheets for Datasets (Gebru et al.)      | Datasheet              | [https://arxiv.org/abs/1803.09010] (Gebru, Crawford, et al., 2018)                             |
| Model Cards for Model Reporting (Mitchell et al.)   | Guidelines            | [https://www.microsoft.com/en-us/research/blog/model-cards-for-model-reporting/] (Mitchell, et al., 2019)           |
| NIST AI Risk Management Framework (AI RMF 1.0)       | Framework             | [https://www.nist.gov/itl/division-13/national-cybersecurity-center-communications/ai-and-machine-learning] (NIST, n.d.)   |
| Official Model Documentation                  | Official Documentation | Varies depending on the specific model being evaluated                          |

## Evidence Table for Dataset Representativeness

| Source Name         | Source Type    | URL or Reference                              | Excerpt (Verbatim Quote)                                                       | Relevance to L4-1 Dataset Coverage   | Notes on Limitations or Bias          |
|---------------------|---------------|----------------------------------------------|-------------------------------------------------------------------------------|---------------------------------------|----------------------------------------|
| Gebru et al. (2018) | Datasheet     | [https://arxiv.org/abs/1803.09010]           | "We report the following statistics for the training and validation sets: ... "  | Demographic coverage, Sampling methodology | Incomplete data on race, gender, and age |
| Mitchell et al. (2019) | Guidelines    | [https://www.microsoft.com/en-us/research/blog/model-cards-for-model-reporting/]   | "... Describe the demographic representation of your training data, including any steps you took to ensure that it is representative. ..." | Demographic coverage                      | Varies depending on the specific model being evaluated |
| NIST AI RMF (1.0)    | Framework     | [https://www.nist.gov/itl/division-13/national-cybersecurity-center-communications/ai-and-machine-learning] | "The AI Risk Management Framework provides guidelines for managing the risks associated with the development, deployment and use of artificial intelligence (AI) systems." | Geographic representation              | -                                     |
| Official Model Documentation    | Official Documentation | Varies depending on the specific model being evaluated | "... We used a dataset consisting of [insert details about data collection] to train our model. ..." | Sampling and data collection procedures   | Data limitations may not be explicitly stated         |

## Analysis of Coverage for each dimension

### Demographic coverage

The Datasheets for Datasets by Gebru et al. (2018) provide an example of a dataset's demographic representation, with statistics for the training and validation sets reported in their work. However, they acknowledge limitations in the data, specifically incomplete data on race, gender, and age.

Model Cards for Model Reporting (Mitchell et al., 2019) emphasize the importance of describing demographic representation within the training data, but the specifics vary depending on the model being evaluated. Officially published documentation for various models provides details about their respective datasets' demographic coverage.

### Geographic / locale representation

The NIST AI Risk Management Framework (AI RMF 1.0) addresses geographical representation by providing guidelines for managing the risks associated with AI systems, but it does not specifically discuss dataset geographic/locale representation. Similarly, Model Cards for Model Reporting focus on demographic coverage without explicitly mentioning geographic or locale distribution.

Official documentation for specific models may provide information about where data was collected, providing some insight into the geographic or locale representation within the datasets.

### Language distribution and accessibility

Model Cards for Model Reporting (Mitchell et al., 2019) encourage the reporting of language distribution within training datasets as part of their guidelines. The Datasheets for Datasets by Gebru et al. (2018) do not explicitly mention language distribution, but the dataset they describe is a multilingual one.

Official documentation for specific models may also provide details about the languages represented in their respective datasets.

### Sampling methodology

The Datasheets for Datasets by Gebru et al. (2018) provide an example of how to report sampling methodology, including details such as data collection procedures and dataset size. Model Cards for Model Reporting (Mitchell et al., 2019) also emphasize the importance of describing the steps taken to ensure that training data is representative.

Official documentation for specific models provides details about their sampling methodology, including any preprocessing or filtering techniques applied.

### Dataset limitations

The Datasheets for Datasets by Gebru et al. (2018) report limitations in the dataset's demographic coverage, specifically incomplete data on race, gender, and age. Model Cards for Model Reporting (Mitchell et al., 2019) encourage the reporting of any known limitations within training datasets but do not provide specific examples.

Official documentation for specific models may also disclose dataset limitations, such as bias, skewed distributions, or underrepresentation in certain demographics or geographic regions.